{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7nFepodHBsGB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis de datos para estadísticas"
      ],
      "metadata": {
        "id": "z4EuADPt5Mph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Datos de consultas**\n",
        "Subir el archivo \"Registro de consultas de usuarios 2025 (respuestas).xls\" sin modificar nada."
      ],
      "metadata": {
        "id": "7nFepodHBsGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# --- NUEVA SECCIÓN: Análisis de Consultas ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Análisis de Consultas por Mes ---\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- 1. Cargar el archivo de consultas ---\n",
        "print(\"Por favor, sube el archivo de la hoja de cálculo de consultas (desde formulario de Google).\")\n",
        "uploaded_consultas = files.upload()\n",
        "\n",
        "# Verificar si se subió algún archivo\n",
        "if not uploaded_consultas:\n",
        "    print(\"No se subió ningún archivo. Saliendo del análisis de consultas.\")\n",
        "else:\n",
        "    # Obtener el nombre del archivo subido\n",
        "    file_name_consultas = next(iter(uploaded_consultas))\n",
        "    print(f\"Archivo '{file_name_consultas}' subido exitosamente.\")\n",
        "\n",
        "    # --- 2. Leer la hoja de cálculo ---\n",
        "    try:\n",
        "        # Leer como Excel (.xls o .xlsx)\n",
        "        df_consultas = pd.read_excel(io.BytesIO(uploaded_consultas[file_name_consultas]))\n",
        "\n",
        "        # --- 3. Validar y preparar datos ---\n",
        "        # Nombres exactos de las columnas según la descripción\n",
        "        required_columns_consultas = [\n",
        "            'Marca temporal',\n",
        "            'Tipo de usuario',\n",
        "            'Medio de consulta',\n",
        "            'Sala de lectura',\n",
        "            'Referencia',\n",
        "            'Servicios de digitalización internos',\n",
        "            'Venta de publicaciones y merchandising',\n",
        "            'Uso de la colección'\n",
        "            # 'Número de matrícula' no se incluye ya que no se usa en el análisis\n",
        "        ]\n",
        "\n",
        "        if all(col in df_consultas.columns for col in required_columns_consultas):\n",
        "            # Seleccionar solo las columnas necesarias\n",
        "            df_consultas = df_consultas[required_columns_consultas].copy()\n",
        "\n",
        "            print(\"\\n--- Datos de consultas leídos correctamente ---\")\n",
        "            # Opcional: Imprimir head, columnas, total de registros para verificación\n",
        "            # print(f\"Primeras 5 filas:\\n{df_consultas.head()}\\n\")\n",
        "            # print(f\"Columnas: {df_consultas.columns.tolist()}\\n\")\n",
        "            # print(f\"Total de registros: {len(df_consultas)}\\n\")\n",
        "\n",
        "            # Convertir 'Marca temporal' a formato datetime\n",
        "            # errors='coerce' convertirá las fechas inválidas a NaT (Not a Time)\n",
        "            df_consultas['Marca temporal'] = pd.to_datetime(df_consultas['Marca temporal'], errors='coerce')\n",
        "\n",
        "            # Eliminar filas con fechas inválidas si es necesario (o se ignorarán en el filtro por mes)\n",
        "            df_consultas.dropna(subset=['Marca temporal'], inplace=True)\n",
        "\n",
        "\n",
        "            # Convertir columnas numéricas y manejar posibles errores o valores vacíos\n",
        "            numeric_cols = ['Servicios de digitalización internos', 'Venta de publicaciones y merchandising']\n",
        "            for col in numeric_cols:\n",
        "                # Asegurarse de que la columna existe antes de procesarla\n",
        "                if col in df_consultas.columns:\n",
        "                    df_consultas[col] = pd.to_numeric(df_consultas[col], errors='coerce').fillna(0).astype(int) # Convertir a número, NaN a 0, y luego a entero\n",
        "                else:\n",
        "                    print(f\"Advertencia: Columna numérica esperada '{col}' no encontrada.\")\n",
        "\n",
        "\n",
        "            # --- 4. Solicitar el mes a analizar al usuario ---\n",
        "            while True:\n",
        "                try:\n",
        "                    mes_analizar = int(input(\"Ingresa el número del mes que deseas analizar (1-12): \"))\n",
        "                    if 1 <= mes_analizar <= 12:\n",
        "                        break # Salir del bucle si el mes es válido\n",
        "                    else:\n",
        "                        print(\"Número de mes inválido. Por favor, ingresa un número entre 1 y 12.\")\n",
        "                except ValueError:\n",
        "                    print(\"Entrada no válida. Por favor, ingresa un número.\")\n",
        "\n",
        "            print(f\"\\nAnalizando datos para el mes: {mes_analizar}\")\n",
        "\n",
        "            # --- 5. Filtrar datos por el mes seleccionado ---\n",
        "            df_mes = df_consultas[df_consultas['Marca temporal'].dt.month == mes_analizar].copy()\n",
        "\n",
        "            if df_mes.empty:\n",
        "                print(f\"\\nNo se encontraron registros para el mes {mes_analizar}.\")\n",
        "            else:\n",
        "                print(f\"\\nSe encontraron {len(df_mes)} registros para el mes {mes_analizar}.\\n\")\n",
        "\n",
        "                # --- 6. Generar la tabla de resultados ---\n",
        "                print(\"--- Resultados del Análisis del Mes ---\")\n",
        "\n",
        "                # 6.1) Tipo de usuario: cantidad de ocurrencias de cada valor (sin incluir NaN)\n",
        "                print(\"\\nTipo de usuario:\")\n",
        "                # MODIFICADO: Eliminado dropna=False\n",
        "                print(df_mes['Tipo de usuario'].value_counts())\n",
        "\n",
        "                # 6.2) Medio de consulta: cantidad de ocurrencias de cada valor (sin incluir NaN)\n",
        "                print(\"\\nMedio de consulta:\")\n",
        "                 # MODIFICADO: Eliminado dropna=False\n",
        "                print(df_mes['Medio de consulta'].value_counts())\n",
        "\n",
        "                # 6.3) Sala de lectura: cantidad de ocurrencias de cada valor (sin incluir NaN)\n",
        "                print(\"\\nSala de lectura:\")\n",
        "                 # MODIFICADO: Eliminado dropna=False\n",
        "                print(df_mes['Sala de lectura'].value_counts())\n",
        "\n",
        "                # 6.4) Referencia: cantidad de ocurrencias de cada valor (sin incluir NaN)\n",
        "                print(\"\\nReferencia:\")\n",
        "                 # MODIFICADO: Eliminado dropna=False\n",
        "                print(df_mes['Referencia'].value_counts())\n",
        "\n",
        "                # 6.5) Servicios de digitalización internos: sumatoria de los datos\n",
        "                print(\"\\nTotal de Servicios de digitalización internos (horas):\")\n",
        "                print(df_mes['Servicios de digitalización internos'].sum())\n",
        "\n",
        "                # 6.6) Venta de publicaciones y merchandising: sumatoria de los datos\n",
        "                print(\"\\nTotal de Venta de publicaciones y merchandising (ítems):\")\n",
        "                print(df_mes['Venta de publicaciones y merchandising'].sum())\n",
        "\n",
        "                # 6.7) Uso de la colección: solo la cantidad de ocurrencias del valor “Reclamo”\n",
        "                print(\"\\nUso de la colección - Cantidad de 'Reclamo':\")\n",
        "                # Asegurarse de que la columna es string antes de comparar\n",
        "                conteo_reclamos = df_mes[df_mes['Uso de la colección'].astype(str) == 'Reclamo'].shape[0]\n",
        "                print(conteo_reclamos)\n",
        "\n",
        "                print(\"\\n\" + \"-\" * 40) # Separador de fin de análisis del mes\n",
        "\n",
        "            # Opcional: Restablecer opciones de visualización de pandas si se modificaron antes\n",
        "            # pd.reset_option('display.max_rows')\n",
        "            # pd.reset_option('display.max_columns')\n",
        "            # pd.reset_option('display.expand_frame_repr')\n",
        "            # pd.reset_option('display.max_colwidth')\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"\\nError: No se encontraron todas las columnas requeridas en el archivo de consultas.\")\n",
        "            print(f\"Columnas esperadas: {required_columns_consultas}\")\n",
        "            print(f\"Columnas encontradas: {df_consultas.columns.tolist()}\")\n",
        "            print(\"Por favor, verifica que los nombres de las columnas en tu archivo coincidan exactamente.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: El archivo '{file_name_consultas}' no fue encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error al procesar el archivo de consultas: {e}\")"
      ],
      "metadata": {
        "id": "2gDFM2t_FSqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Datos de Selección Informativa, Web y Redes Sociales**\n",
        "Subir el archivo \"DSI - Comunicación - Redes Sociales 2025 (respuestas).xls\" sin modificar nada."
      ],
      "metadata": {
        "id": "z8Mch6oEF41m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# --- NUEVA SECCIÓN: Análisis de Comunicaciones ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Análisis de Comunicaciones por Mes ---\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- 1. Cargar el archivo de comunicaciones ---\n",
        "print(\"Por favor, sube el archivo de la hoja de cálculo de comunicaciones (newsletters, posteos, etc.).\")\n",
        "uploaded_comunicaciones = files.upload()\n",
        "\n",
        "# Verificar si se subió algún archivo\n",
        "if not uploaded_comunicaciones:\n",
        "    print(\"No se subió ningún archivo. Saliendo del análisis de comunicaciones.\")\n",
        "else:\n",
        "    # Obtener el nombre del archivo subido\n",
        "    file_name_comunicaciones = next(iter(uploaded_comunicaciones))\n",
        "    print(f\"Archivo '{file_name_comunicaciones}' subido exitosamente.\")\n",
        "\n",
        "    # --- 2. Leer la hoja de cálculo ---\n",
        "    try:\n",
        "        # Leer como Excel (.xls o .xlsx)\n",
        "        df_comunicaciones = pd.read_excel(io.BytesIO(uploaded_comunicaciones[file_name_comunicaciones]))\n",
        "\n",
        "        # --- 3. Validar y preparar datos ---\n",
        "        # Nombres exactos de las columnas según la descripción\n",
        "        required_columns_comunicaciones = [\n",
        "            'Marca temporal',\n",
        "            'Cantidad de correos enviados',\n",
        "            'Noticias',\n",
        "            'Boletín',\n",
        "            'Sitio web',\n",
        "            'Posteos en Facebook',\n",
        "            'Posteos en Instagram',\n",
        "            'Posteos en Twitter',\n",
        "            'Posteos en YouTube',\n",
        "            'Posteos en Issuu'\n",
        "        ]\n",
        "\n",
        "        if all(col in df_comunicaciones.columns for col in required_columns_comunicaciones):\n",
        "            # Seleccionar solo las columnas necesarias\n",
        "            df_comunicaciones = df_comunicaciones[required_columns_comunicaciones].copy()\n",
        "\n",
        "            print(\"\\n--- Datos de comunicaciones leídos correctamente ---\")\n",
        "            # Opcional: Imprimir head, columnas, total de registros para verificación\n",
        "            # print(f\"Primeras 5 filas:\\n{df_comunicaciones.head()}\\n\")\n",
        "            # print(f\"Columnas: {df_comunicaciones.columns.tolist()}\\n\")\n",
        "            # print(f\"Total de registros: {len(df_comunicaciones)}\\n\")\n",
        "\n",
        "            # Convertir 'Marca temporal' a formato datetime\n",
        "            df_comunicaciones['Marca temporal'] = pd.to_datetime(df_comunicaciones['Marca temporal'], errors='coerce')\n",
        "\n",
        "            # Eliminar filas con fechas inválidas si es necesario (o se ignorarán en el filtro por mes)\n",
        "            df_comunicaciones.dropna(subset=['Marca temporal'], inplace=True)\n",
        "\n",
        "            # Identificar columnas a sumar (todas excepto 'Marca temporal')\n",
        "            columns_to_sum = [col for col in required_columns_comunicaciones if col != 'Marca temporal']\n",
        "\n",
        "            # Convertir columnas a sumar a numérico, tratar errores como 0\n",
        "            for col in columns_to_sum:\n",
        "                # Asegurarse de que la columna existe antes de procesarla (ya validado, pero extra seguro)\n",
        "                if col in df_comunicaciones.columns:\n",
        "                     df_comunicaciones[col] = pd.to_numeric(df_comunicaciones[col], errors='coerce').fillna(0).astype(int)\n",
        "                else:\n",
        "                     print(f\"Advertencia: Columna esperada '{col}' no encontrada para sumar.\")\n",
        "\n",
        "\n",
        "            # --- 4. Solicitar el mes a analizar al usuario ---\n",
        "            while True:\n",
        "                try:\n",
        "                    mes_analizar_com = int(input(\"Ingresa el número del mes que deseas analizar (1-12): \"))\n",
        "                    if 1 <= mes_analizar_com <= 12:\n",
        "                        break # Salir del bucle si el mes es válido\n",
        "                    else:\n",
        "                        print(\"Número de mes inválido. Por favor, ingresa un número entre 1 y 12.\")\n",
        "                except ValueError:\n",
        "                    print(\"Entrada no válida. Por favor, ingresa un número.\")\n",
        "\n",
        "            print(f\"\\nAnalizando datos para el mes: {mes_analizar_com}\")\n",
        "\n",
        "            # --- 5. Filtrar datos por el mes seleccionado ---\n",
        "            df_com_mes = df_comunicaciones[df_comunicaciones['Marca temporal'].dt.month == mes_analizar_com].copy()\n",
        "\n",
        "            if df_com_mes.empty:\n",
        "                print(f\"\\nNo se encontraron registros para el mes {mes_analizar_com}.\")\n",
        "            else:\n",
        "                print(f\"\\nSe encontraron {len(df_com_mes)} registros para el mes {mes_analizar_com}.\\n\")\n",
        "\n",
        "                # --- 6. Calcular la sumatoria por columna ---\n",
        "                # Seleccionar solo las columnas numéricas del DataFrame filtrado y sumar\n",
        "                sumatorias_com = df_com_mes[columns_to_sum].sum()\n",
        "\n",
        "                # --- 7. Generar la tabla de resultados ---\n",
        "                # Convertir la Serie de sumatorias a un DataFrame\n",
        "                tabla_sumarias_com = sumatorias_com.reset_index()\n",
        "                tabla_sumarias_com.columns = ['Ítem', 'Total en el mes'] # Renombrar columnas\n",
        "\n",
        "                # --- 8. Mostrar la tabla final ---\n",
        "                print(\"--- Sumatoria de Comunicaciones por Ítem en el Mes ---\")\n",
        "\n",
        "                # Ajustar opciones de visualización si es necesario (aunque esta tabla es pequeña)\n",
        "                pd.set_option('display.max_rows', None)\n",
        "                pd.set_option('display.max_columns', None)\n",
        "                pd.set_option('display.expand_frame_repr', False)\n",
        "                pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "                print(tabla_sumarias_com)\n",
        "                print(\"\\n\" + \"-\" * 40) # Separador de fin de análisis\n",
        "\n",
        "            # Opcional: Restablecer opciones de visualización\n",
        "            # pd.reset_option('display.max_rows')\n",
        "            # pd.reset_option('display.max_columns')\n",
        "            # pd.reset_option('display.expand_frame_repr')\n",
        "            # pd.reset_option('display.max_colwidth')\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"\\nError: No se encontraron todas las columnas requeridas en el archivo de comunicaciones.\")\n",
        "            print(f\"Columnas esperadas: {required_columns_comunicaciones}\")\n",
        "            print(f\"Columnas encontradas: {df_comunicaciones.columns.tolist()}\")\n",
        "            print(\"Por favor, verifica que los nombres de las columnas en tu archivo coincidan exactamente.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: El archivo '{file_name_comunicaciones}' no fue encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error al procesar el archivo de comunicaciones: {e}\")"
      ],
      "metadata": {
        "id": "lEbsBRY3ILDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Datos de circulación**\n",
        "Eliminar del archivo “circulación.xls” todas las columnas excepto Destino, Nivel bibliográfico, Título y Autor."
      ],
      "metadata": {
        "id": "vwAJF1S75ShV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tma5wgDK5LCu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# --- 1. Cargar el archivo ---\n",
        "print(\"Por favor, sube el archivo de la hoja de cálculo de circulación.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verificar si se subió algún archivo\n",
        "if not uploaded:\n",
        "    print(\"No se subió ningún archivo. Saliendo del script.\")\n",
        "else:\n",
        "    # Obtener el nombre del archivo subido (asumimos que solo se sube uno)\n",
        "    file_name = next(iter(uploaded))\n",
        "    print(f\"Archivo '{file_name}' subido exitosamente.\")\n",
        "\n",
        "    # --- 2. Leer la hoja de cálculo ---\n",
        "    try:\n",
        "        # Intentar leer como Excel (.xlsx)\n",
        "        if file_name.endswith('.xlsx'):\n",
        "            df = pd.read_excel(io.BytesIO(uploaded[file_name]))\n",
        "        # Intentar leer como CSV (.csv) si no es Excel\n",
        "        elif file_name.endswith('.csv'):\n",
        "             # Puedes ajustar el delimitador si es necesario (ej: sep=';')\n",
        "            df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "        else:\n",
        "            print(\"Formato de archivo no soportado. Por favor sube un archivo .xlsx o .csv\")\n",
        "            df = None # Asegurarse de que df sea None si el formato no es válido\n",
        "\n",
        "        if df is not None:\n",
        "            # --- 3. Renombrar columnas para facilitar el acceso (ajusta si tus nombres son ligeramente diferentes) ---\n",
        "            # Intenta encontrar las columnas por nombre o por posición si sabes que siempre están en las mismas.\n",
        "            # Aquí asumimos los nombres exactos proporcionados: 'Destino', 'Nivel bibliográfico', 'Título', 'Autor/es'\n",
        "            # Puedes añadir lógica para encontrar columnas si los nombres varían ligeramente.\n",
        "            required_columns = ['Destino', 'Nivel Bibliografico', 'Título', 'Autor Principal']\n",
        "            if all(col in df.columns for col in required_columns):\n",
        "                df = df[required_columns] # Seleccionar solo las columnas que necesitamos\n",
        "                df.columns = ['Destino', 'Nivel_Bibliografico', 'Titulo', 'Autor_es'] # Renombrar a nombres más amigables para Python\n",
        "\n",
        "                print(\"\\n--- Datos leídos correctamente ---\")\n",
        "                print(f\"Total de registros: {len(df)}\\n\")\n",
        "\n",
        "                # --- 4. Realizar los análisis ---\n",
        "\n",
        "                # 4.1) Sumatoria de los destinos de préstamo, discriminados por nivel bibliográfico.\n",
        "                print(\"--- 1) Sumatoria de destinos de préstamo por nivel bibliográfico ---\")\n",
        "                # Usar pivot_table para una tabla resumen limpia\n",
        "                tabla_destinos_por_nivel = df.pivot_table(\n",
        "                    index='Destino',\n",
        "                    columns='Nivel_Bibliografico',\n",
        "                    aggfunc='size', # Cuenta el número de filas en cada grupo\n",
        "                    fill_value=0    # Rellenar combinaciones sin datos con 0\n",
        "                )\n",
        "                # Asegurarse de que las columnas 'X' y 'M' existan aunque no haya datos para una de ellas\n",
        "                for nivel in ['X', 'M']:\n",
        "                    if nivel not in tabla_destinos_por_nivel.columns:\n",
        "                         tabla_destinos_por_nivel[nivel] = 0\n",
        "\n",
        "                # Reordenar columnas para que M y X (o viceversa) estén consistentemente\n",
        "                column_order = [col for col in ['M', 'X'] if col in tabla_destinos_por_nivel.columns]\n",
        "                other_cols = [col for col in tabla_destinos_por_nivel.columns if col not in column_order]\n",
        "                tabla_destinos_por_nivel = tabla_destinos_por_nivel[column_order + other_cols]\n",
        "\n",
        "\n",
        "                print(tabla_destinos_por_nivel)\n",
        "                print(\"-\" * 40) # Separador\n",
        "\n",
        "                # 4.2) Para cada título de revista (nivel X) la cantidad de préstamos para destino.\n",
        "                print(\"\\n--- 2) Conteo de préstamos por destino para cada título de revista (Nivel X) ---\")\n",
        "                # Filtrar solo las filas donde Nivel_Bibliografico es 'X'\n",
        "                df_revistas = df[df['Nivel_Bibliografico'] == 'X'].copy()\n",
        "\n",
        "                if not df_revistas.empty:\n",
        "                    # Agrupar por Título y Destino y contar\n",
        "                    conteo_revistas_por_destino = df_revistas.groupby(['Titulo', 'Destino']).size().reset_index(name='Cantidad_Prestamos')\n",
        "\n",
        "                    # --- AÑADIR ESTAS LÍNEAS ANTES DE IMPRIMIR LA TABLA ---\n",
        "                    # Configurar opciones de visualización de pandas para mostrar todas las filas y columnas (si caben)\n",
        "                    pd.set_option('display.max_rows', None)\n",
        "                    pd.set_option('display.max_columns', None)\n",
        "                    pd.set_option('display.expand_frame_repr', False) # Evitar que la tabla se envuelva si es ancha\n",
        "                    pd.set_option('display.max_colwidth', None) # Evitar que el contenido de las celdas se trunque\n",
        "\n",
        "                    # Mostrar la tabla plana (Título, Destino, Cantidad)\n",
        "                    print(conteo_revistas_por_destino)\n",
        "\n",
        "                    # --- Opcional: Restablecer las opciones por defecto después de imprimir ---\n",
        "                    # pd.reset_option('display.max_rows')\n",
        "                    # pd.reset_option('display.max_columns')\n",
        "                    # pd.reset_option('display.expand_frame_repr')\n",
        "                    # pd.reset_option('display.max_colwidth')\n",
        "\n",
        "\n",
        "                else:\n",
        "                    print(\"No se encontraron registros con 'Nivel bibliográfico' = 'X'.\")\n",
        "\n",
        "                print(\"-\" * 40) # Separador\n",
        "\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"\\nError: No se encontraron todas las columnas requeridas ('Destino', 'Nivel bibliográfico', 'Título', 'Autor/es') en el archivo.\")\n",
        "                print(f\"Columnas encontradas: {df.columns.tolist()}\")\n",
        "                print(\"Por favor, verifica que los nombres de las columnas en tu archivo coincidan exactamente.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: El archivo '{file_name}' no fue encontrado (esto no debería ocurrir si se subió correctamente).\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error al procesar el archivo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temas consultados anual\n",
        "Pasar los datos del txt a una planilla de cálculo, eliminar el texto y dejar las columnas Total y Materia."
      ],
      "metadata": {
        "id": "fBCgraBY84FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import re # Necesario para limpiar la cadena CDU\n",
        "\n",
        "# --- 0. Diccionario de Temas CDU ---\n",
        "# Este diccionario debe estar incluido en el script\n",
        "temas_CDU = {\n",
        "    '34:711.5': 'Derecho de la Edificación',\n",
        "    '331.45': 'Seguridad en el trabajo',\n",
        "    '332.72': 'Mercado inmobiliario',\n",
        "    '332.82': 'Política Habitacional',\n",
        "    '341.233.1': 'Fideicomisos',\n",
        "    '342.72': 'Derechos de los Ciudadanos',\n",
        "    '347': 'Derecho Civil',\n",
        "    '347.238.3': 'Propiedad Horizontal',\n",
        "    '347.4': 'Contratos',\n",
        "    '347.51': 'Responsabilidad Civil',\n",
        "    '347.513': 'Daños',\n",
        "    '347.56': 'Responsabilidad Profesional',\n",
        "    '347.948': 'Peritajes',\n",
        "    '349.443': 'Ejercicio profesional',\n",
        "    '352': 'Administración Pública',\n",
        "    '378:72': 'Enseñanza de la arquitectura',\n",
        "    '504.61': 'Impacto Ambiental',\n",
        "    '534.84': 'Acústica arquitectónica',\n",
        "    '535.6': 'Color',\n",
        "    '556.18': 'Recursos Hídricos',\n",
        "    '614.841.3': 'Instalaciones y seguridad c/incendio',\n",
        "    '624': 'Ingeniería Civil',\n",
        "    '624:69': 'Construcciones Civiles',\n",
        "    '624.01': 'Estructuras',\n",
        "    '624.012.45': 'Estructuras de hormigón',\n",
        "    '624.014': 'Estructuras metálicas',\n",
        "    '624.13': 'Geotecnia',\n",
        "    '624.014.2': 'Estructuras de acero',\n",
        "    '624.15': 'Cimentaciones',\n",
        "    '65.012': 'Gerenciamiento de Proyectos',\n",
        "    '65.012.4': 'Gestión de la calidad',\n",
        "    '65.013': 'Dirección de obras',\n",
        "    '657.31': 'Cómputos, costos y presupuestos',\n",
        "    '657.47': 'Costos de obra',\n",
        "    '657.92': 'Tasaciones',\n",
        "    '658': 'Administración de empresas',\n",
        "    '658.56': 'Control de Calidad',\n",
        "    '658.8:72': 'Marketing para arquitectos',\n",
        "    '681.3': 'Sistemas informáticos p/arq.',\n",
        "    '69': 'Construcciones',\n",
        "    '69-05': 'Organización de obras',\n",
        "    '69.057': 'Construcciones prefabricadas',\n",
        "    '69.059': 'Mantenimiento edilicio',\n",
        "    '69.059.2': 'Patologías',\n",
        "    '691.11': 'Madera',\n",
        "    '691.32': 'Hormigón',\n",
        "    '691.41': 'Construcción con adobe',\n",
        "    '692.2': 'Medianería',\n",
        "    '692.23': 'Fachadas',\n",
        "    '692.4': 'Cubiertas',\n",
        "    '692.6': 'Escaleras',\n",
        "    '692.71': 'Parrillas',\n",
        "    '696.1': 'Instalaciones sanitarias',\n",
        "    '696.2': 'Instalaciones de Gas',\n",
        "    '696.6': 'Instalaciones eléctricas',\n",
        "    '697': 'Climatización',\n",
        "    '7.01': 'Estética',\n",
        "    '7.013': 'Feng Shui',\n",
        "    '711:93': 'Historia urbana de las ciudades',\n",
        "    '711.1': 'Planificación Urbana',\n",
        "    '711.146': 'Espacio público',\n",
        "    '711.16': 'Planes Estratégicos',\n",
        "    '711.163': 'Proyectos urbanos',\n",
        "    '711.16:504': 'Planes Urbanos Ambientales',\n",
        "    '711.24': 'Planificación Territorial',\n",
        "    '711.4': 'Planificación Urbana',\n",
        "    '711.41': 'Diseño Urbano',\n",
        "    '711.42': 'Gestión Urbana',\n",
        "    '711.5': 'Barrios',\n",
        "    '711.51': 'Códigos de Planeamiento',\n",
        "    '711.58': 'Asentamientos',\n",
        "    '711.6': 'Códigos de Edificación',\n",
        "    '711.62': 'Códigos de Habilitaciones',\n",
        "    '711.73': 'Vías de circulación',\n",
        "    '711.8': 'Infraestructura de servicios',\n",
        "    '711.95': 'Ecología urbana',\n",
        "    '712': 'Paisajismo',\n",
        "    '712.23': 'Áreas costeras',\n",
        "    '719': 'Patrimonio urbano',\n",
        "    '72:34': 'Arquitectura legal',\n",
        "    '72(079)': 'Concursos',\n",
        "    '72(82)': 'Arquitectura argentina',\n",
        "    '72(821.1)': 'Arquitectura de Buenos Aires',\n",
        "    '72-057': 'Biografías de Arquitectos',\n",
        "    '72.01': 'Teoría arquitectónica',\n",
        "    '72.011': 'Documentación de obra',\n",
        "    '72.025': 'Patrimonio arquitectónico',\n",
        "    '72.03': 'Estilos Arquitectónicos',\n",
        "    '72.036': 'Arquitectura Moderna',\n",
        "    '72.039': 'Arquitectura Contemporánea',\n",
        "    '72.039.28': 'Arquitectura Sustentable',\n",
        "    '72.057': 'Cocinas',\n",
        "    '720': 'Estudios de Arquitectura',\n",
        "    '725.23': 'Oficinas',\n",
        "    '725.51': 'Arquitectura Hospitalaria',\n",
        "    '725.54': 'Barreras Arquitectónicas', # Corregido (asumo Barreras)\n",
        "    '725.58': 'Accesibilidad',\n",
        "    '725.82': 'Teatros',\n",
        "    '727.7': 'Museos',\n",
        "    '728': 'Viviendas',\n",
        "    '728.1': 'Vivienda Social',\n",
        "    '728.2': 'Viviendas Multifamiliares',\n",
        "    '728.3': 'Viviendas Unifamiliares',\n",
        "    '741': 'Dibujo arquitectónico',\n",
        "    '821': 'Literatura',\n",
        "    '93': 'Historia'\n",
        "}\n",
        "\n",
        "\n",
        "# --- NUEVA SECCIÓN: Análisis de Temas Consultados por CDU ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Análisis de Temas Consultados por CDU ---\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- 1. Cargar el archivo de temas consultados ---\n",
        "print(\"Por favor, sube el archivo de la hoja de cálculo de temas consultados.\")\n",
        "uploaded_temas = files.upload()\n",
        "\n",
        "# Verificar si se subió algún archivo\n",
        "if not uploaded_temas:\n",
        "    print(\"No se subió ningún archivo. Saliendo del análisis de temas.\")\n",
        "else:\n",
        "    # Obtener el nombre del archivo subido\n",
        "    file_name_temas = next(iter(uploaded_temas))\n",
        "    print(f\"Archivo '{file_name_temas}' subido exitosamente.\")\n",
        "\n",
        "    # --- 2. Leer la hoja de cálculo ---\n",
        "    try:\n",
        "        # Leer como Excel (.xls o .xlsx)\n",
        "        df_temas = pd.read_excel(io.BytesIO(uploaded_temas[file_name_temas]))\n",
        "\n",
        "        # --- 3. Validar y preparar datos ---\n",
        "        required_columns_temas = ['TOTAL', 'MATERIA']\n",
        "        if all(col in df_temas.columns for col in required_columns_temas):\n",
        "            df_temas = df_temas[required_columns_temas].copy() # Seleccionar y copiar para evitar advertencias\n",
        "            df_temas.columns = ['Total_Obras', 'CDU_Completa'] # Renombrar\n",
        "\n",
        "            print(\"\\n--- Datos de temas leídos correctamente ---\")\n",
        "            # Puedes dejar estas líneas de verificación si quieres, o borrarlas como dijimos antes\n",
        "            # print(f\"Primeras 5 filas:\\n{df_temas.head()}\\n\")\n",
        "            # print(f\"Columnas: {df_temas.columns.tolist()}\\n\")\n",
        "            # print(f\"Total de registros: {len(df_temas)}\\n\")\n",
        "\n",
        "\n",
        "            # Asegurarse de que la columna 'Total_Obras' sea numérica\n",
        "            df_temas['Total_Obras'] = pd.to_numeric(df_temas['Total_Obras'], errors='coerce')\n",
        "            # Eliminar filas donde 'Total_Obras' no pudo convertirse a número (NaN) o es NaN\n",
        "            df_temas.dropna(subset=['Total_Obras'], inplace=True)\n",
        "             # Convertir Total_Obras a entero si no tiene decimales (opcional, para que se vea más limpio)\n",
        "            df_temas['Total_Obras'] = df_temas['Total_Obras'].astype(int)\n",
        "\n",
        "            # Asegurarse de que la columna 'CDU_Completa' sea string para aplicar replace\n",
        "            df_temas['CDU_Completa'] = df_temas['CDU_Completa'].astype(str)\n",
        "\n",
        "\n",
        "            # --- 4. Limpiar la columna CDU (remover información desde el primer paréntesis en adelante) ---\n",
        "            # Usamos una expresión regular para encontrar y reemplazar patrones como \"(...\" hasta el final\n",
        "            df_temas['CDU_Principal'] = df_temas['CDU_Completa'].str.replace(r'\\(.*$', '', regex=True).str.strip()\n",
        "\n",
        "            # Eliminar filas donde la CDU principal quedó vacía después de la limpieza\n",
        "            df_temas.dropna(subset=['CDU_Principal'], inplace=True)\n",
        "            df_temas = df_temas[df_temas['CDU_Principal'] != ''].copy()\n",
        "\n",
        "            # print(\"--- CDU limpiada ---\")\n",
        "            # print(f\"Primeras 5 filas con CDU_Principal:\\n{df_temas.head()}\\n\")\n",
        "\n",
        "\n",
        "            # --- 5. Realizar la sumatoria por CDU principal ---\n",
        "            # Agrupar por la CDU principal y sumar la columna 'Total_Obras'\n",
        "            sumatoria_cdu = df_temas.groupby('CDU_Principal')['Total_Obras'].sum()\n",
        "\n",
        "            # --- 6. Ordenar de mayor a menor ---\n",
        "            sumatoria_cdu_sorted = sumatoria_cdu.sort_values(ascending=False)\n",
        "\n",
        "            # --- 7. Seleccionar los 10 primeros puestos ---\n",
        "            top_10_cdu = sumatoria_cdu_sorted.head(10)\n",
        "\n",
        "            # --- 8. Generar la tabla final con nombres de tema ---\n",
        "            # Convertir la Serie a DataFrame\n",
        "            top_10_df = top_10_cdu.reset_index()\n",
        "            top_10_df.columns = ['Número CDU', 'Cantidad de ocurrencias'] # Renombrar columnas\n",
        "\n",
        "            # Mapear el número CDU al nombre del tema usando el diccionario\n",
        "            top_10_df['Nombre del tema'] = top_10_df['Número CDU'].map(temas_CDU)\n",
        "\n",
        "            # --- CORRECCIÓN: Evitar inplace=True para eliminar FutureWarnings ---\n",
        "            top_10_df['Nombre del tema'] = top_10_df['Nombre del tema'].fillna(\"Tema no encontrado en diccionario\")\n",
        "            # --- FIN CORRECCIÓN ---\n",
        "\n",
        "            # Reordenar las columnas a: Número CDU, Nombre del tema, Cantidad de ocurrencias\n",
        "            final_table_temas = top_10_df[['Número CDU', 'Nombre del tema', 'Cantidad de ocurrencias']]\n",
        "\n",
        "\n",
        "            # --- 9. Mostrar la tabla final ---\n",
        "            print(\"\\n--- 3) Top 10 Temas más Consultados por CDU ---\")\n",
        "\n",
        "            # Ajustar opciones de visualización\n",
        "            pd.set_option('display.max_rows', None)\n",
        "            pd.set_option('display.max_columns', None)\n",
        "            pd.set_option('display.expand_frame_repr', False)\n",
        "            pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "            print(final_table_temas)\n",
        "            print(\"-\" * 40) # Separador\n",
        "\n",
        "            # Opcional: Restablecer opciones\n",
        "            # pd.reset_option('display.max_rows')\n",
        "            # pd.reset_option('display.max_columns')\n",
        "            # pd.reset_option('display.expand_frame_repr')\n",
        "            # pd.reset_option('display.max_colwidth')\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"\\nError: No se encontraron todas las columnas requeridas ('TOTAL', 'MATERIA') en el archivo de temas.\")\n",
        "            print(f\"Columnas encontradas: {df_temas.columns.tolist()}\")\n",
        "            print(\"Por favor, verifica que los nombres de las columnas en tu archivo coincidan exactamente.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: El archivo '{file_name_temas}' no fue encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error al procesar el archivo de temas: {e}\")"
      ],
      "metadata": {
        "id": "ATQGw3NUBJsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KDJWNjXQCL3t"
      }
    }
  ]
}